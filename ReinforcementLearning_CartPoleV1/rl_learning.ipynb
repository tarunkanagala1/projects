{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CMAY1TpjTfSl",
        "outputId": "c325655a-99a0-4716-d55e-9b6d5b6f9de7"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.12.0\n",
        "!pip install gym==0.25.2\n",
        "!pip install keras\n",
        "!pip install keras-rl2==1.0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GH2gDNr-VXU8"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HtiwnEpxWtBl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEjSBRvPW3eT",
        "outputId": "fb86d3f4-b78e-48a9-e246-31a7773f9db0"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20.*\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWp-dJPTUA7M",
        "outputId": "a91f446b-badc-4a18-fd89-bad4153b9f6a"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1',render_mode='human')\n",
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G0hIDWTSWvby"
      },
      "outputs": [],
      "source": [
        "#Creating a Sequential Keras Model \n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,states)))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(actions, activation='linear'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BgtfYFsMfp-Z"
      },
      "outputs": [],
      "source": [
        "#Creating agent and setting up a policy for it \n",
        "agent=DQNAgent(\n",
        "    model=model,\n",
        "    memory=SequentialMemory(limit=50000,window_length=1),\n",
        "    policy=BoltzmannQPolicy(),\n",
        "    nb_actions=actions,\n",
        "    nb_steps_warmup=10,\n",
        "    target_model_update=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A88oLfUQin6R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers.legacy import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Ek5p04gW4f",
        "outputId": "70649a86-4efe-46f3-b08c-9275af0d775b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "    7/10000 [..............................] - ETA: 3:40 - reward: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   10/10000 [..............................] - ETA: 3:33 - reward: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   21/10000 [..............................] - ETA: 7:17 - reward: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   30/10000 [..............................] - ETA: 6:10 - reward: 1.0000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.10/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 204s 20ms/step - reward: 1.0000\n",
            "97 episodes - episode_reward: 102.289 [8.000, 320.000] - loss: 3.238 - mae: 19.889 - mean_q: 40.428\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 202s 20ms/step - reward: 1.0000\n",
            "41 episodes - episode_reward: 244.073 [179.000, 389.000] - loss: 4.689 - mae: 42.707 - mean_q: 86.568\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 202s 20ms/step - reward: 1.0000\n",
            "43 episodes - episode_reward: 230.116 [157.000, 370.000] - loss: 3.817 - mae: 47.837 - mean_q: 96.611\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 202s 20ms/step - reward: 1.0000\n",
            "38 episodes - episode_reward: 262.684 [162.000, 397.000] - loss: 2.588 - mae: 45.840 - mean_q: 92.448\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 202s 20ms/step - reward: 1.0000\n",
            "done, took 1014.609 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7accb1847820>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#The model is currently trained for 50k steps but can be changed for more accurate model\n",
        "agent.compile(Adam(learning_rate=0.001),metrics=[\"mae\"])\n",
        "agent.fit(env,nb_steps=50000,visualize=False,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsAm5DbLg0cp",
        "outputId": "cc695b26-4c0e-4dc7-dcb1-e84ceffcd4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 50 episodes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1: reward: 224.000, steps: 224\n",
            "Episode 2: reward: 500.000, steps: 500\n",
            "Episode 3: reward: 195.000, steps: 195\n",
            "Episode 4: reward: 224.000, steps: 224\n",
            "Episode 5: reward: 433.000, steps: 433\n",
            "Episode 6: reward: 241.000, steps: 241\n",
            "Episode 7: reward: 214.000, steps: 214\n",
            "Episode 8: reward: 438.000, steps: 438\n",
            "Episode 9: reward: 243.000, steps: 243\n",
            "Episode 10: reward: 189.000, steps: 189\n",
            "Episode 11: reward: 477.000, steps: 477\n",
            "Episode 12: reward: 390.000, steps: 390\n",
            "Episode 13: reward: 500.000, steps: 500\n",
            "Episode 14: reward: 288.000, steps: 288\n",
            "Episode 15: reward: 246.000, steps: 246\n",
            "Episode 16: reward: 389.000, steps: 389\n",
            "Episode 17: reward: 373.000, steps: 373\n",
            "Episode 18: reward: 253.000, steps: 253\n",
            "Episode 19: reward: 293.000, steps: 293\n",
            "Episode 20: reward: 234.000, steps: 234\n",
            "Episode 21: reward: 404.000, steps: 404\n",
            "Episode 22: reward: 305.000, steps: 305\n",
            "Episode 23: reward: 207.000, steps: 207\n",
            "Episode 24: reward: 500.000, steps: 500\n",
            "Episode 25: reward: 499.000, steps: 499\n",
            "Episode 26: reward: 443.000, steps: 443\n",
            "Episode 27: reward: 240.000, steps: 240\n",
            "Episode 28: reward: 484.000, steps: 484\n",
            "Episode 29: reward: 470.000, steps: 470\n",
            "Episode 30: reward: 438.000, steps: 438\n",
            "Episode 31: reward: 242.000, steps: 242\n",
            "Episode 32: reward: 489.000, steps: 489\n",
            "Episode 33: reward: 280.000, steps: 280\n",
            "Episode 34: reward: 500.000, steps: 500\n",
            "Episode 35: reward: 199.000, steps: 199\n",
            "Episode 36: reward: 496.000, steps: 496\n",
            "Episode 37: reward: 424.000, steps: 424\n",
            "Episode 38: reward: 251.000, steps: 251\n",
            "Episode 39: reward: 457.000, steps: 457\n",
            "Episode 40: reward: 500.000, steps: 500\n",
            "Episode 41: reward: 500.000, steps: 500\n",
            "Episode 42: reward: 500.000, steps: 500\n",
            "Episode 43: reward: 226.000, steps: 226\n",
            "Episode 44: reward: 276.000, steps: 276\n",
            "Episode 45: reward: 500.000, steps: 500\n",
            "Episode 46: reward: 455.000, steps: 455\n",
            "Episode 47: reward: 454.000, steps: 454\n",
            "Episode 48: reward: 250.000, steps: 250\n",
            "Episode 49: reward: 461.000, steps: 461\n",
            "Episode 50: reward: 500.000, steps: 500\n",
            "365.88\n"
          ]
        }
      ],
      "source": [
        "#Testing the model for 50 sequences/episodes \n",
        "results=agent.test(env,nb_episodes=50,visualize=True)\n",
        "print(np.mean(results.history[\"episode_reward\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "B67d4gcNks5a"
      },
      "outputs": [],
      "source": [
        "# Saves model in high,rich Keras format\n",
        "model.save('model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DLhWK5Aii9A3"
      },
      "outputs": [],
      "source": [
        "# Saves model in low hd5 format\n",
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zV39vIP3hNa_"
      },
      "outputs": [],
      "source": [
        "#Closing the environment\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
